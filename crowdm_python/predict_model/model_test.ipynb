{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "# import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from models.normal_head import NormalHead\n",
    "from models.translayer import Transformer\n",
    "from dataset_loader import *\n",
    "from utils import set_seed, save_best_record\n",
    "from losses import loss_computer\n",
    "from models import WSAD\n",
    "from options import parse_args\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args):\n",
    "    net = WSAD(args.len_feature, flag=\"Test\", args=args)\n",
    "    net = net.cuda()\n",
    "    model_checkpoint = os.path.join(args.model_path, \"./ckpts/xd_best.pkl\")\n",
    "    net.load_state_dict(torch.load(model_checkpoint))\n",
    "    net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(args):\n",
    "    test_loader = data.DataLoader(\n",
    "        XDVideo(root_dir=args.root_dir, mode='Test', num_segments=args.num_segments, len_feature=args.len_feature),\n",
    "        batch_size=1,  # Process one video at a time for visualization purposes\n",
    "        shuffle=False, num_workers=args.num_workers,\n",
    "        worker_init_fn=None)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(frames, scores):\n",
    "    num_frames = len(frames)\n",
    "    for i in range(num_frames):\n",
    "        frame = frames[i]\n",
    "        score = scores[i]\n",
    "\n",
    "        # Normalize score for visualization\n",
    "        normalized_score = int(score * 255)\n",
    "\n",
    "        # Convert frame to BGR format for OpenCV\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Display score on the frame\n",
    "        cv2.putText(frame_bgr, f'Score: {score:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Frame', frame_bgr)\n",
    "\n",
    "        # Pause to create video effect, press any key to move to the next frame\n",
    "        cv2.waitKey(30)\n",
    "\n",
    "    # Release the video window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_visualize(net, test_loader):\n",
    "    with torch.no_grad():\n",
    "        for step, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Assuming outputs contain scores for each frame\n",
    "            scores = outputs.squeeze().cpu().numpy()\n",
    "\n",
    "            # Load the video frames (assuming inputs is the video tensor)\n",
    "            video_frames = inputs.squeeze().cpu().numpy()  # Shape: (num_frames, height, width, channels)\n",
    "            \n",
    "            # Visualize results\n",
    "            visualize_results(video_frames, scores)\n",
    "            break  # Remove this break to process all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    if args.seed >= 0:\n",
    "        set_seed(args.seed)\n",
    "    \n",
    "    # Load model\n",
    "    net = load_model(args)\n",
    "    \n",
    "    # Load test data\n",
    "    test_loader = load_test_data(args)\n",
    "    \n",
    "    # Predict and visualize\n",
    "    predict_and_visualize(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and apply it to video data\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    if args.debug:\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "    args.log_path = os.path.join(args.log_path, 'ckpts', 'xd', args.version)\n",
    "    args.model_path = os.path.join(args.model_path, 'ckpts', 'xd', args.version)\n",
    "\n",
    "    if not os.path.exists(args.log_path):\n",
    "        os.makedirs(args.log_path)\n",
    "    if not os.path.exists(args.model_path):\n",
    "        os.makedirs(args.model_path)\n",
    "\n",
    "    # wandb.init(\n",
    "    #     project=\"BN-WVAD\",\n",
    "    #     name=args.version,\n",
    "    #     config={\n",
    "    #         'optimization:lr': args.lr[0],\n",
    "    #         'optimization:iters': args.num_iters,\n",
    "    #         'dataset:dataset': 'xd-violence',\n",
    "    #         'model:kernel_sizes': args.kernel_sizes,\n",
    "    #         'model:channel_ratios': args.ratios,\n",
    "    #         'triplet_loss:abn_ratio_sample': args.ratio_sample,\n",
    "    #         'triplet_loss:abn_ratio_batch': args.ratio_batch,\n",
    "    #     },\n",
    "    #     settings=wandb.Settings(code_dir=os.path.dirname(os.path.abspath(__file__))),\n",
    "    #     save_code=True,\n",
    "    # )\n",
    "\n",
    "    worker_init_fn = None\n",
    "\n",
    "    if args.seed >= 0:\n",
    "        set_seed(args.seed)\n",
    "        worker_init_fn = np.random.seed(args.seed)\n",
    "    \n",
    "    # Initialize model\n",
    "    net = WSAD(args.len_feature, flag=\"Test\", args=args)\n",
    "    net = net.cuda()\n",
    "\n",
    "    # Load the trained model\n",
    "    model_checkpoint = os.path.join(args.model_path, \"../ckpts/xd_best.pkl\")\n",
    "    net.load_state_dict(torch.load(model_checkpoint))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Load test data\n",
    "    test_loader = data.DataLoader(\n",
    "        XDVideo(root_dir=args.root_dir, mode='Test', num_segments=args.num_segments, len_feature=args.len_feature),\n",
    "        batch_size=5,\n",
    "        shuffle=False, num_workers=args.num_workers,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "    # Perform evaluation\n",
    "    test_info = {'step': [], 'AUC': [], 'AP': []}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # Compute metrics (AUC, AP, etc.) here\n",
    "            # Assuming you have a function `compute_metrics` to calculate AUC and AP\n",
    "            auc, ap = compute_metrics(outputs, labels)\n",
    "            \n",
    "            test_info['step'].append(step)\n",
    "            test_info['AUC'].append(auc)\n",
    "            test_info['AP'].append(ap)\n",
    "            \n",
    "            print(f\"Step: {step}, AUC: {auc}, AP: {ap}\")\n",
    "\n",
    "    # Print or save the final evaluation results\n",
    "    print(\"Final Test Results:\", test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aivle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
